{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://localhost:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='http://localhost:8787/status' target='_blank'>http://localhost:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>134.99 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://144.92.142.182:8786' processes=6 threads=12, memory=134.99 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from distributed import Client\n",
    "# client = await Client(\"localhost:8786\", asynchronous=True)\n",
    "client = Client(\"localhost:8786\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_file(\"train.py\")\n",
    "client.upload_file(\"tune.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_covtype(return_X_y=True, shuffle=False, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 54)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_poly = kernel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 1485)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_poly, y, random_state=42, train_size=200_000,\n",
    "#     X_poly, y, random_state=42, train_size=20_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.212822437286377"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.nbytes / 1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 1485)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 613)\n",
      "(200000, 613)\n"
     ]
    }
   ],
   "source": [
    "def _get_cnts_cols(X):\n",
    "    cols = range(X.shape[1])\n",
    "    uniqs = [np.unique(X[:, c]) for c in cols]\n",
    "    cnts = [c for c, _u in zip(cols, uniqs) if len(_u) > 2]\n",
    "    discrete_cols = [c for c, _u in zip(cols, uniqs) if len(_u) == 2]\n",
    "    return cnts, discrete_cols\n",
    "\n",
    "def normalize(X, scale, cnts, discrete):\n",
    "    Y = scale.transform(X[:, cnts])\n",
    "    Y2 = X[:, discrete].astype(bool).astype(int)  # one element is 30 (not 0/1)\n",
    "    Z = np.hstack((Y2, Y))\n",
    "    return Z\n",
    "\n",
    "cnts, discrete = _get_cnts_cols(X_train)\n",
    "scale = StandardScaler().fit(X_train[:, cnts])\n",
    "\n",
    "print(X_train[:, cnts + discrete].shape)\n",
    "X_train = normalize(X_train, scale, cnts, discrete)\n",
    "X_test = normalize(X_test, scale, cnts, discrete)\n",
    "print(X_train.shape)\n",
    "\n",
    "uniqs = np.unique(X_train[:, :len(discrete)])\n",
    "assert len(uniqs) == 2 and 0 <= uniqs.min() <= uniqs.max() <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 613)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(381012, 613)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "def train(damper, X_train=None, y_train=None, X_test=None, y_test=None, max_iter=200, ident=\"foo\"):\n",
    "    damper.initialize()\n",
    "    test_score = damper.score(X_test, y_test, return_dict=True, prefix=\"test_\")\n",
    "    train_score = damper.score(X_train, y_train, return_dict=True, prefix=\"train_\")\n",
    "    meta = {\n",
    "        \"train_eg\": len(y_train),\n",
    "        \"test_eg\": len(y_test),\n",
    "        \"max_iter\": max_iter,\n",
    "        \"damper_name\": type(damper).__name__.lower(),\n",
    "        **damper.get_params(),\n",
    "    }\n",
    "    data = [{\"partial_fit_calls\": 0, **test_score, **train_score, **meta, **copy(damper.meta_)}]\n",
    "    print(\"ident =\", ident)\n",
    "    pprint({k: data[-1][k] for k in [\"test_acc\", \"train_acc\", \"test_loss\", \"train_loss\"]})\n",
    "    for k in itertools.count():\n",
    "        damper.partial_fit(X_train, y_train)\n",
    "        test_score =  damper.score(X_test, y_test, return_dict=True, prefix=\"test_\")\n",
    "        train_score =  damper.score(X_train, y_train, return_dict=True, prefix=\"train_\")\n",
    "        datum = {\n",
    "            \"partial_fit_calls\": k + 1,\n",
    "            \"epochs\": copy(damper.meta_[\"num_examples\"] / meta[\"train_eg\"]),\n",
    "            \"ident\": ident,\n",
    "            **meta,\n",
    "            **test_score,\n",
    "            **train_score,\n",
    "            **copy(damper.meta_)\n",
    "        }\n",
    "        cols = [\n",
    "            \"name\", \"epochs\", \"model_updates\",\n",
    "            \"test_acc\", \"test_loss\", \"ident\",\n",
    "        ]\n",
    "        show = {k: datum[k]\n",
    "                for k in cols\n",
    "                if k in datum\n",
    "               }\n",
    "        print(show)\n",
    "        data.append(datum)\n",
    "        if ident == \"gd\" or k % 100 == 0:\n",
    "            pd.DataFrame(data).to_csv(f\"/mnt/ws/home/ssievert/exp-cnvx/tmp-{ident}-test-data.csv\")\n",
    "        if datum[\"epochs\"] >= max_iter:\n",
    "            break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "base = {\n",
    "    \"lr\": 0.9e-3,\n",
    "    \"max_batch_size\": 256,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"momentum\": 0.9,\n",
    "    \"seed\": 33,\n",
    "}\n",
    "\n",
    "pada_params = {\n",
    "    **copy(base),\n",
    "    \"batch_growth_rate\": 0.08192397984251328,\n",
    "    \"dwell\": 5,\n",
    "    \"initial_batch_size\": 256,\n",
    "    \"max_batch_size\": 2048,\n",
    "}\n",
    "\n",
    "hsgd_params = {\n",
    "    **copy(pada_params),\n",
    "    \"batch_growth_rate\": 0.011471883405287283,\n",
    "    \"max_batch_size\": len(X_train),\n",
    "}\n",
    "\n",
    "padalr_params = {\n",
    "    **copy(pada_params),\n",
    "    \"static_batch_size\": 256\n",
    "}\n",
    "\n",
    "gd_params = {\n",
    "    **copy(base),\n",
    "    \"max_batch_size\": int(200e3),\n",
    "}\n",
    "\n",
    "asgd_params = {\n",
    "    **copy(base),\n",
    "    \"opt\": \"asgd\",\n",
    "}\n",
    "\n",
    "for k in [\"initial_batch_size\", \"max_batch_size\"]:\n",
    "    _ = padalr_params.pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0009,\n",
       " 'max_batch_size': 2048,\n",
       " 'weight_decay': 1e-06,\n",
       " 'momentum': 0.9,\n",
       " 'seed': 33,\n",
       " 'batch_growth_rate': 0.011471883405287283,\n",
       " 'dwell': 5,\n",
       " 'initial_batch_size': 256}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsgd_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tune import GD, PadaDamp, Damper, PadaDampLR, HSGD\n",
    "\n",
    "gd = GD(name=\"gd\", **gd_params)\n",
    "pada = PadaDamp(name=\"pada\", **pada_params)\n",
    "hsgd = HSGD(name=\"hsgd\", **hsgd_params)\n",
    "padalr = PadaDampLR(name=\"padalr\", **padalr_params)\n",
    "asgd = Damper(name=\"asgd\", **asgd_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pada\n",
      "padalr\n",
      "asgd\n"
     ]
    }
   ],
   "source": [
    "from distributed import as_completed\n",
    "\n",
    "dataset = dict(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    ")\n",
    "\n",
    "dask_dataset = {k: client.scatter(v) for k, v in dataset.items()}\n",
    "\n",
    "max_iter = 2000\n",
    "# max_iter = 200\n",
    "# dampers = {\"pada\": pada, \"padalr\": padalr, \"asgd\": asgd}\n",
    "dampers = {\"hsgd\": hsgd}\n",
    "\n",
    "futures = []\n",
    "for ident, damper in dampers.items():\n",
    "    print(ident)\n",
    "    future = client.submit(train, damper, **dask_dataset, max_iter=max_iter, ident=ident)\n",
    "    futures.append(future)\n",
    "\n",
    "# future = client.submit(train, gd, **dask_dataset, max_iter=max_iter * 120, ident=\"gd\")\n",
    "# futures.append(future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: pending, key: train-b807c209b161520cf08c525abc5811d9>,\n",
       " <Future: pending, key: train-6217a58adb8cf2abd0a976656fa13a28>,\n",
       " <Future: pending, key: train-6b8ac2b8395091182afeed59dda98481>,\n",
       " <Future: pending, key: train-635fb9841f68c0f3e5b8a3ca18e5e069>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'acc': 0.112255,\n",
      " 'batch_size': 256,\n",
      " 'damper_name': 'damper',\n",
      " 'damping': 256,\n",
      " 'device': 'cpu',\n",
      " 'epochs': 2000.1984,\n",
      " 'ident': 'asgd',\n",
      " 'len_dataset': 200000,\n",
      " 'loss': 2.2170941633605956,\n",
      " 'lr': 0.0009,\n",
      " 'lr_': 0.0009,\n",
      " 'max_batch_size': 256,\n",
      " 'max_iter': 2000,\n",
      " 'model_updates': 1562655,\n",
      " 'momentum': 0.9,\n",
      " 'name': 'asgd',\n",
      " 'num_examples': 400039680,\n",
      " 'opt': 'asgd',\n",
      " 'partial_fit_calls': 2218,\n",
      " 'scoring': 'loss',\n",
      " 'seed': 33,\n",
      " 'test_acc': 0.7584826724617597,\n",
      " 'test_eg': 381012,\n",
      " 'test_loss': 0.5576608569390787,\n",
      " 'train_acc': 0.76126,\n",
      " 'train_eg': 200000,\n",
      " 'train_loss': 0.5508005522537232,\n",
      " 'weight_decay': 1e-06}\n",
      "1\n",
      "{'acc': 0.095735,\n",
      " 'batch_growth_rate': 0.08192397984251328,\n",
      " 'batch_size': 256,\n",
      " 'damper_name': 'padadamplr',\n",
      " 'damping': 128275,\n",
      " 'device': 'cpu',\n",
      " 'dwell': 5,\n",
      " 'epochs': 2000.1984,\n",
      " 'ident': 'padalr',\n",
      " 'len_dataset': 200000,\n",
      " 'loss': 2.197520377197266,\n",
      " 'lr': 0.0009,\n",
      " 'lr_': 1.796141103098811e-06,\n",
      " 'max_iter': 2000,\n",
      " 'model_updates': 1562655,\n",
      " 'momentum': 0.9,\n",
      " 'name': 'padalr',\n",
      " 'num_examples': 400039680,\n",
      " 'pada_damping': 128275,\n",
      " 'partial_fit_calls': 2218,\n",
      " 'scoring': 'loss',\n",
      " 'seed': 33,\n",
      " 'static_batch_size': 256,\n",
      " 'test_acc': 0.7460421194083126,\n",
      " 'test_eg': 381012,\n",
      " 'test_loss': 0.5945359072522497,\n",
      " 'train_acc': 0.74819,\n",
      " 'train_eg': 200000,\n",
      " 'train_loss': 0.5885768342590332,\n",
      " 'weight_decay': 1e-06}\n",
      "2\n",
      "{'acc': 0.112255,\n",
      " 'batch_growth_rate': 0.08192397984251328,\n",
      " 'batch_size': 2048,\n",
      " 'damper_name': 'padadamp',\n",
      " 'damping': 17045,\n",
      " 'device': 'cpu',\n",
      " 'dwell': 5,\n",
      " 'epochs': 2000.53049,\n",
      " 'ident': 'pada',\n",
      " 'initial_batch_size': 256,\n",
      " 'len_dataset': 200000,\n",
      " 'loss': 2.2170941633605956,\n",
      " 'lr': 0.0009,\n",
      " 'lr_': 0.00010813728366089763,\n",
      " 'max_batch_size': 2048,\n",
      " 'max_iter': 2000,\n",
      " 'model_updates': 204931,\n",
      " 'momentum': 0.9,\n",
      " 'name': 'pada',\n",
      " 'num_examples': 400106098,\n",
      " 'pada_damping': 17045,\n",
      " 'partial_fit_calls': 2218,\n",
      " 'scoring': 'loss',\n",
      " 'seed': 33,\n",
      " 'test_acc': 0.7554355243404407,\n",
      " 'test_eg': 381012,\n",
      " 'test_loss': 0.5657527381293288,\n",
      " 'train_acc': 0.75788,\n",
      " 'train_eg': 200000,\n",
      " 'train_loss': 0.5591162734222412,\n",
      " 'weight_decay': 1e-06}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for k, future in enumerate(as_completed(futures)):\n",
    "    data = future.result()\n",
    "    print(k)\n",
    "    pprint(data[-1])\n",
    "    pd.DataFrame(data).to_csv(f\"tmp-hsgd-{k}-test-data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skorch]",
   "language": "python",
   "name": "conda-env-skorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
