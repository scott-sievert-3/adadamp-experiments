{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "# client = await Client(\"localhost:8786\", asynchronous=True)\n",
    "client = Client(\"localhost:8786\")\n",
    "# client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_file(\"train.py\")\n",
    "client.upload_file(\"tune.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_covtype(return_X_y=True, shuffle=False, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_poly = kernel.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_poly, y, random_state=42, train_size=200_000,\n",
    "#     X_poly, y, random_state=42, train_size=20_000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.nbytes / 1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_cnts_cols(X):\n",
    "    cols = range(X.shape[1])\n",
    "    uniqs = [np.unique(X[:, c]) for c in cols]\n",
    "    cnts = [c for c, _u in zip(cols, uniqs) if len(_u) > 2]\n",
    "    discrete_cols = [c for c, _u in zip(cols, uniqs) if len(_u) == 2]\n",
    "    return cnts, discrete_cols\n",
    "\n",
    "def normalize(X, scale, cnts, discrete):\n",
    "    Y = scale.transform(X[:, cnts])\n",
    "    Y2 = X[:, discrete].astype(bool).astype(int)  # one element is 30 (not 0/1)\n",
    "    Z = np.hstack((Y2, Y))\n",
    "    return Z\n",
    "\n",
    "cnts, discrete = _get_cnts_cols(X_train)\n",
    "scale = StandardScaler().fit(X_train[:, cnts])\n",
    "\n",
    "print(X_train[:, cnts + discrete].shape)\n",
    "X_train = normalize(X_train, scale, cnts, discrete)\n",
    "X_test = normalize(X_test, scale, cnts, discrete)\n",
    "print(X_train.shape)\n",
    "\n",
    "uniqs = np.unique(X_train[:, :len(discrete)])\n",
    "assert len(uniqs) == 2 and 0 <= uniqs.min() <= uniqs.max() <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "def train(damper, X_train=None, y_train=None, X_test=None, y_test=None, max_iter=200, ident=\"foo\"):\n",
    "    damper.initialize()\n",
    "    test_score = damper.score(X_test, y_test, return_dict=True, prefix=\"test_\")\n",
    "    train_score = damper.score(X_train, y_train, return_dict=True, prefix=\"train_\")\n",
    "    meta = {\n",
    "        \"train_eg\": len(y_train),\n",
    "        \"test_eg\": len(y_test),\n",
    "        \"max_iter\": max_iter,\n",
    "        \"damper_name\": type(damper).__name__.lower(),\n",
    "        **damper.get_params(),\n",
    "    }\n",
    "    data = [{\"partial_fit_calls\": 0, **test_score, **train_score, **meta, **copy(damper.meta_)}]\n",
    "    print(\"ident =\", ident)\n",
    "    pprint({k: data[-1][k] for k in [\"test_acc\", \"train_acc\", \"test_loss\", \"train_loss\"]})\n",
    "    for k in itertools.count():\n",
    "        damper.partial_fit(X_train, y_train)\n",
    "        test_score =  damper.score(X_test, y_test, return_dict=True, prefix=\"test_\")\n",
    "        train_score =  damper.score(X_train, y_train, return_dict=True, prefix=\"train_\")\n",
    "        datum = {\n",
    "            \"partial_fit_calls\": k + 1,\n",
    "            \"epochs\": copy(damper.meta_[\"num_examples\"] / meta[\"train_eg\"]),\n",
    "            \"ident\": ident,\n",
    "            **meta,\n",
    "            **test_score,\n",
    "            **train_score,\n",
    "            **copy(damper.meta_)\n",
    "        }\n",
    "        cols = [\n",
    "            \"name\", \"epochs\", \"model_updates\",\n",
    "            \"test_acc\", \"test_loss\", \"ident\",\n",
    "        ]\n",
    "        show = {k: datum[k]\n",
    "                for k in cols\n",
    "                if k in datum\n",
    "               }\n",
    "        print(show)\n",
    "        data.append(datum)\n",
    "        if ident == \"gd\" or k % 100 == 0:\n",
    "            pd.DataFrame(data).to_csv(f\"tmp-{ident}-test-data.csv\")\n",
    "        if datum[\"epochs\"] >= max_iter:\n",
    "            break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "base = {\n",
    "    \"lr\": 0.9e-3,\n",
    "    \"max_batch_size\": 256,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"momentum\": 0.9,\n",
    "    \"seed\": 33,\n",
    "}\n",
    "\n",
    "pada_params = {\n",
    "    **copy(base),\n",
    "    \"batch_growth_rate\": 0.08192397984251328,\n",
    "    \"dwell\": 5,\n",
    "    \"initial_batch_size\": 256,\n",
    "    \"max_batch_size\": 2048,\n",
    "}\n",
    "\n",
    "hsgd_params = {\n",
    "    **copy(pada_params),\n",
    "    \"batch_growth_rate\": 0.011471883405287283,\n",
    "    \"max_batch_size\": len(X_train),\n",
    "}\n",
    "\n",
    "padalr_params = {\n",
    "    **copy(pada_params),\n",
    "    \"static_batch_size\": 256\n",
    "}\n",
    "\n",
    "gd_params = {\n",
    "    **copy(base),\n",
    "    \"max_batch_size\": int(200e3),\n",
    "}\n",
    "\n",
    "asgd_params = {\n",
    "    **copy(base),\n",
    "    \"opt\": \"asgd\",\n",
    "}\n",
    "\n",
    "geodamp_params = {\n",
    "    **copy(base),\n",
    "    \"dampingdelay\": 200,\n",
    "    \"dampingfactor\": 6.604777577905901,\n",
    "    \"initial_batch_size\": 256,\n",
    "    \"max_batch_size\": 4096,\n",
    "}\n",
    "\n",
    "for k in [\"initial_batch_size\", \"max_batch_size\"]:\n",
    "    _ = padalr_params.pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsgd_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tune import GD, PadaDamp, Damper, PadaDampLR, HSGD, GeoDamp\n",
    "\n",
    "gd = GD(name=\"gd\", **gd_params)\n",
    "pada = PadaDamp(name=\"pada\", **pada_params)\n",
    "hsgd = HSGD(name=\"hsgd\", **hsgd_params)\n",
    "padalr = PadaDampLR(name=\"padalr\", **padalr_params)\n",
    "asgd = Damper(name=\"asgd\", **asgd_params)\n",
    "geo = GeoDamp(name=\"geo\", **geodamp_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import as_completed\n",
    "\n",
    "dataset = dict(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    ")\n",
    "\n",
    "dask_dataset = {k: client.scatter(v) for k, v in dataset.items()}\n",
    "\n",
    "max_iter = 2000\n",
    "# max_iter = 200\n",
    "# dampers = {\"pada\": pada, \"padalr\": padalr, \"asgd\": asgd}\n",
    "# dampers = {\"hsgd\": hsgd}\n",
    "dampers = {\"geo\": geo}\n",
    "\n",
    "futures = []\n",
    "for ident, damper in dampers.items():\n",
    "    print(ident)\n",
    "    future = client.submit(train, damper, **dask_dataset, max_iter=max_iter, ident=ident)\n",
    "    futures.append(future)\n",
    "\n",
    "# future = client.submit(train, gd, **dask_dataset, max_iter=max_iter * 120, ident=\"gd\")\n",
    "# futures.append(future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for k, future in enumerate(as_completed(futures)):\n",
    "    data = future.result()\n",
    "    print(k)\n",
    "    pprint(data[-1])\n",
    "    pd.DataFrame(data).to_csv(f\"tmp-geo-{k}-test-data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!open ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:skorch]",
   "language": "python",
   "name": "conda-env-skorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
