{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Wide ResNet with Dask Classifier\n",
    "\n",
    "- Rerun LR decrease starting with 0.05\n",
    "- Rerun BS increase starting with 0.05\n",
    "- Run 2nd/3rd hybrid exps\n",
    "\n",
    "Make simple dist.py that reads from CSV. \n",
    "- Subclass dask classifier to return based on training CSV\n",
    "- sleep during partial_fit, override to sleep on diff workers\n",
    "- Overwrite score and _get_grads ( to sleep )\n",
    "--- Function called "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/joeholt/Developer/next-lab/adadamp-experiments/')\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "from copy import copy\n",
    "from adadamp.adadamp import DaskClassifier, DaskClassifierExpiriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://192.168.0.103/56690/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.0.103:8787/status' target='_blank'>http://192.168.0.103:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://192.168.0.103/56690/1' processes=1 threads=8, memory=17.18 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training client\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import performance_report\n",
    "\n",
    "def _prep():\n",
    "    from distributed.protocol import torch\n",
    "\n",
    "client = Client(processes=False)\n",
    "client.run(_prep)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/joeholt/Developer/next-lab/adadamp-experiments'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Wide_ResNet\n",
    "\n",
    "client.upload_file(\"./exp-dask/model.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set = torchvision.datasets.CIFAR10(root='./exp-dask/data', train=True, download=True, transform=transform_train)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./exp-dask/data', train=False, download=True, transform=transform_test)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for expiriment 1: \n",
    "#    “Decaying learning rate” follows the original implementation; \n",
    "#     the batch size is constant, while the learning rate repeatedly \n",
    "#     decays by a factor of 5 at a sequence of steps\n",
    "# my understanding is that this is the \"control\" expeririment, where we are not touching the number of \n",
    "# workers nor the batch size\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "args = dict(\n",
    "    module=Wide_ResNet,\n",
    "    module__depth=16,\n",
    "    module__widen_factor=4,\n",
    "    module__dropout_rate=0.3,\n",
    "    module__num_classes=len(classes),\n",
    "    loss=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer__lr=0.1,\n",
    "    optimizer__momentum=0.9,\n",
    "    optimizer__nesterov=True,\n",
    "    optimizer__weight_decay=0.5e-3,\n",
    "    batch_size=128,\n",
    "    max_epochs=200,\n",
    "    device=device,\n",
    "    grads_per_worker=128,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v0 - broken dist.py, LR 1\n",
    "# v1 - fixed dist.py, LR 1\n",
    "# v2 - LR 0.02\n",
    "# v3 - LR 0.02, decaying learning rate, fixed data load\n",
    "\n",
    "def write_stats(hist, exp, epoch):\n",
    "    toCSV = hist\n",
    "    with open('./exp-dask/stats/{}/exp-{}.csv'.format(exp, epoch), 'w', encoding='utf8', newline='') as output_file:\n",
    "        fc = csv.DictWriter(output_file, fieldnames=toCSV[0].keys())\n",
    "        fc.writeheader()\n",
    "        fc.writerows(toCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, model, test_set):\n",
    "    \"\"\"\n",
    "    tests if model meets certain testing standards:\n",
    "    - by 10th epoch, accuracy is over 70%\n",
    "    \"\"\"\n",
    "    if epoch == 10:\n",
    "        print(\"[TEST] Testing accuracy for 10th epoch is over 70%\")\n",
    "        score = model.score(test_set)\n",
    "        acc = model._meta['score__acc']\n",
    "        if acc < 0.70:\n",
    "            print(\"[TEST] Test failed with {} accuracy\".format(acc))\n",
    "            return False\n",
    "        else:\n",
    "            print(\"[TEST] Test passed with {} accuracy\".format(acc))\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_set, test_set, n_epochs=200, epoch_sched=[], lr_sched=[], bs_sched=[], log_interval=1, exp='increasing-bs'):\n",
    "    \"\"\"\n",
    "    Train based on expiriment params\n",
    "    \n",
    "    Parameters:\n",
    "    epoch_sched: update lr and bs at epochs in this list\n",
    "    lr_sched: update lr to value at matching epoch. Should be same length as epoch_sched\n",
    "    bs_sched: update bs to value at matching epoch. Should be same length as epoch_sched\n",
    "    \"\"\"\n",
    "    assert len(epoch_sched) == len(lr_sched) == len(bs_sched), \"Invalid schedules. Epoch, lr and bs schedules should all be the same length.\"\n",
    "    \n",
    "    epochs = copy(epoch_sched)\n",
    "    lrs = copy(lr_sched)\n",
    "    bss = copy(bs_sched)\n",
    "    \n",
    "    history = []\n",
    "    for epoch in range(n_epochs):\n",
    "        # check for updates\n",
    "        if len(epochs) > 0 and epochs[0] == epoch:\n",
    "            lr = lrs.pop(0)\n",
    "            bs = bss.pop(0)\n",
    "            epochs.pop(0)\n",
    "            model.set_lr(lr)\n",
    "            model.set_bs(bs)\n",
    "            print(\"[UPDATE] Updated model params:\\n\\tlr: {}\\n\\tbs: {}\".format(lr, bs))\n",
    "            if epoch != 0:\n",
    "                print(\"[UPDATE] Running loss on train set...\", end=\" \")\n",
    "                train_score = model.score(train_set)\n",
    "                print(model._meta['score__loss'], '(acc:', model._meta['score__acc'], ')')\n",
    "        # run\n",
    "        print(\"[Epoch {}]\".format(epoch), end=\"\")\n",
    "        model.partial_fit(train_set)\n",
    "        score = model.score(test_set)\n",
    "        datum = {\"epoch\": epoch, \"score\": score, **model.get_params(), **model.meta_}\n",
    "        print(\" Score: {}\".format(score))\n",
    "        history.append(datum)\n",
    "        \n",
    "        # test\n",
    "        if test(epoch, model, test_set) == False:\n",
    "            print(\"[TEST] Test failed, exiting\")\n",
    "            break\n",
    "        \n",
    "        if epoch % log_interval == 0:\n",
    "            write_stats(history, exp, 'ep{}'.format(epoch))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ie \"Update LR to 0.1 and bs t0 640 on 60th epoch\"\n",
    "exp0_epochs = [0, 60, 120, 180]\n",
    "exp0_lr = [\n",
    "    0.05, \n",
    "    0.05 / 5, \n",
    "    0.05 / 5 / 5, \n",
    "    0.05 / 5 / 5 / 5\n",
    "]\n",
    "exp0_bs = [128, 128, 128, 128]\n",
    "model = DaskClassifierExpiriments(**args)\n",
    "# train\n",
    "hist = None\n",
    "with performance_report(filename=\"dask-report.html\"):\n",
    "    hist = train(model, \n",
    "             train_set, \n",
    "             test_set, \n",
    "             n_epochs=200, \n",
    "             epoch_sched=exp0_epochs, \n",
    "             lr_sched=exp0_lr, \n",
    "             bs_sched=exp0_bs, \n",
    "             log_interval=20,\n",
    "             exp='decreasing-lr'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_stats(hist, 'decreasing-lr', '-final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.05\n",
      "\tbs: 128\n",
      "[Epoch 0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/adadamp-experiments/adadamp/adadamp/_dist.py:185: UserWarning: Model appears not to update with weight difference {diff}\n",
      "  warn(\"Model appears not to update with weight difference {diff}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score: 0.5943999886512756\n",
      "[Epoch 1] Score: 0.6757999658584595\n",
      "[Epoch 2] Score: 0.7128999829292297\n",
      "[Epoch 3] Score: 0.7423999905586243\n",
      "[Epoch 4] Score: 0.770799994468689\n",
      "[Epoch 5] Score: 0.7875999808311462\n",
      "[Epoch 6] Score: 0.7892999649047852\n",
      "[Epoch 7] Score: 0.8071999549865723\n",
      "[Epoch 8] Score: 0.8120999932289124\n",
      "[Epoch 9] Score: 0.8226000070571899\n",
      "[Epoch 10] Score: 0.8353999853134155\n",
      "[TEST] Testing accuracy for 10th epoch is over 70%\n",
      "[TEST] Test passed with 0.8330999612808228 accuracy\n",
      "[Epoch 11] Score: 0.8224999904632568\n",
      "[Epoch 12] Score: 0.8246999979019165\n",
      "[Epoch 13] Score: 0.8355000019073486\n",
      "[Epoch 14] Score: 0.8416999578475952\n",
      "[Epoch 15] Score: 0.8370999693870544\n",
      "[Epoch 16] Score: 0.8308999538421631\n",
      "[Epoch 17] Score: 0.8429999947547913\n",
      "[Epoch 18] Score: 0.8490999937057495\n",
      "[Epoch 19] Score: 0.8333999514579773\n",
      "[Epoch 20] Score: 0.8337999582290649\n",
      "[Epoch 21] Score: 0.848800003528595\n",
      "[Epoch 22] Score: 0.8454999923706055\n",
      "[Epoch 23] Score: 0.8416000008583069\n",
      "[Epoch 24] Score: 0.8499000072479248\n",
      "[Epoch 25] Score: 0.8327999711036682\n",
      "[Epoch 26] Score: 0.8413999676704407\n",
      "[Epoch 27] Score: 0.852400004863739\n",
      "[Epoch 28] Score: 0.8547999858856201\n",
      "[Epoch 29] Score: 0.8568999767303467\n",
      "[Epoch 30] Score: 0.8453999757766724\n",
      "[Epoch 31] Score: 0.840399980545044\n",
      "[Epoch 32] Score: 0.8412999510765076\n",
      "[Epoch 33] Score: 0.8478999733924866\n",
      "[Epoch 34] Score: 0.8452999591827393\n",
      "[Epoch 35] Score: 0.8649999499320984\n",
      "[Epoch 36] Score: 0.8551999926567078\n",
      "[Epoch 37] Score: 0.8543999791145325\n",
      "[Epoch 38] Score: 0.8586999773979187\n",
      "[Epoch 39] Score: 0.865399956703186\n",
      "[Epoch 40] Score: 0.8592999577522278\n",
      "[Epoch 41] Score: 0.8407999873161316\n",
      "[Epoch 42] Score: 0.8537999987602234\n",
      "[Epoch 43] Score: 0.8513000011444092\n",
      "[Epoch 44] Score: 0.8481000065803528\n",
      "[Epoch 45] Score: 0.8567000031471252\n",
      "[Epoch 46] Score: 0.8639999628067017\n",
      "[Epoch 47] Score: 0.8431999683380127\n",
      "[Epoch 48] Score: 0.8543999791145325\n",
      "[Epoch 49] Score: 0.852400004863739\n",
      "[Epoch 50] Score: 0.8549000024795532\n",
      "[Epoch 51] Score: 0.8651999831199646\n",
      "[Epoch 52] Score: 0.8666999936103821\n",
      "[Epoch 53] Score: 0.8619999885559082\n",
      "[Epoch 54] Score: 0.8587999939918518\n",
      "[Epoch 55] Score: 0.8686999678611755\n",
      "[Epoch 56] Score: 0.8454999923706055\n",
      "[Epoch 57] Score: 0.8610000014305115\n",
      "[Epoch 58] Score: 0.8483999967575073\n",
      "[Epoch 59] Score: 0.8626999855041504\n",
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.05\n",
      "\tbs: 640\n",
      "[UPDATE] Running loss on train set... 0.2565148910522461 (acc: 0.9102999567985535 )\n",
      "[Epoch 60] Score: 0.8992999792098999\n",
      "[Epoch 61] Score: 0.9009000062942505\n",
      "[Epoch 62] Score: 0.9041000008583069\n",
      "[Epoch 63] Score: 0.9016000032424927\n",
      "[Epoch 64] Score: 0.9034000039100647\n",
      "[Epoch 65] Score: 0.9043999910354614\n",
      "[Epoch 66] Score: 0.8982999920845032\n",
      "[Epoch 67] Score: 0.9031999707221985\n",
      "[Epoch 68] Score: 0.901199996471405\n",
      "[Epoch 69] Score: 0.9036999940872192\n",
      "[Epoch 70] Score: 0.9037999510765076\n",
      "[Epoch 71] Score: 0.9036999940872192\n",
      "[Epoch 72] Score: 0.8992999792098999\n",
      "[Epoch 73] Score: 0.8991000056266785\n",
      "[Epoch 74] Score: 0.9055999517440796\n",
      "[Epoch 75] Score: 0.8977999687194824\n",
      "[Epoch 76] Score: 0.9049999713897705\n",
      "[Epoch 77] Score: 0.904699981212616\n",
      "[Epoch 78] Score: 0.8973999619483948\n",
      "[Epoch 79] Score: 0.8944000005722046\n",
      "[Epoch 80] Score: 0.9034000039100647\n",
      "[Epoch 81] Score: 0.8962000012397766\n",
      "[Epoch 82] Score: 0.9007999897003174\n",
      "[Epoch 83] Score: 0.899399995803833\n",
      "[Epoch 84] Score: 0.8974999785423279\n",
      "[Epoch 85] Score: 0.899899959564209\n",
      "[Epoch 86] Score: 0.8951999545097351\n",
      "[Epoch 87] Score: 0.898099958896637\n",
      "[Epoch 88] Score: 0.8941999673843384\n",
      "[Epoch 89] Score: 0.9006999731063843\n",
      "[Epoch 90] Score: 0.9005999565124512\n",
      "[Epoch 91] Score: 0.8937999606132507\n",
      "[Epoch 92] Score: 0.8999999761581421\n",
      "[Epoch 93] Score: 0.8914999961853027\n",
      "[Epoch 94] Score: 0.9020999670028687\n",
      "[Epoch 95] Score: 0.8905999660491943\n",
      "[Epoch 96] Score: 0.8987999558448792\n",
      "[Epoch 97] Score: 0.8937000036239624\n",
      "[Epoch 98] Score: 0.8995999693870544\n",
      "[Epoch 99] Score: 0.8983999490737915\n",
      "[Epoch 100] Score: 0.8938999772071838\n",
      "[Epoch 101] Score: 0.9003999829292297\n",
      "[Epoch 102] Score: 0.8926999568939209\n",
      "[Epoch 103] Score: 0.8941999673843384\n",
      "[Epoch 104] Score: 0.8940999507904053\n",
      "[Epoch 105] Score: 0.8876999616622925\n",
      "[Epoch 106] Score: 0.8996999859809875\n",
      "[Epoch 107] Score: 0.8935999870300293\n",
      "[Epoch 108] Score: 0.8922999501228333\n",
      "[Epoch 109] Score: 0.9016000032424927\n",
      "[Epoch 110] Score: 0.8944999575614929\n",
      "[Epoch 111] Score: 0.8937000036239624\n",
      "[Epoch 112] Score: 0.8992999792098999\n",
      "[Epoch 113] Score: 0.8871999979019165\n",
      "[Epoch 114] Score: 0.8931999802589417\n",
      "[Epoch 115] Score: 0.9005999565124512\n",
      "[Epoch 116] Score: 0.8984999656677246\n",
      "[Epoch 117] Score: 0.8996999859809875\n",
      "[Epoch 118] Score: 0.9010999798774719\n",
      "[Epoch 119] Score: 0.8912000060081482\n",
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.05\n",
      "\tbs: 3200\n",
      "[UPDATE] Running loss on train set... 0.07068052124023437 (acc: 0.9778599739074707 )\n",
      "[Epoch 120] Score: 0.9077999591827393\n",
      "[Epoch 121] Score: 0.9150999784469604\n",
      "[Epoch 122] Score: 0.9139999747276306\n",
      "[Epoch 123] Score: 0.9156999588012695\n",
      "[Epoch 124] Score: 0.9145999550819397\n",
      "[Epoch 125] Score: 0.9190999865531921\n",
      "[Epoch 126] Score: 0.915399968624115\n",
      "[Epoch 127] Score: 0.9175999760627747\n",
      "[Epoch 128] Score: 0.9182999730110168\n",
      "[Epoch 129] Score: 0.9162999987602234\n",
      "[Epoch 130] Score: 0.9181999564170837\n",
      "[Epoch 131] Score: 0.9160999655723572\n",
      "[Epoch 132] Score: 0.9211999773979187\n",
      "[Epoch 133] Score: 0.9194999933242798\n",
      "[Epoch 134] Score: 0.91839998960495\n",
      "[Epoch 135] Score: 0.9156999588012695\n",
      "[Epoch 136] Score: 0.9160999655723572\n",
      "[Epoch 137] Score: 0.9164999723434448\n",
      "[Epoch 138] Score: 0.9177999496459961\n",
      "[Epoch 139] Score: 0.9160999655723572\n",
      "[Epoch 140] Score: 0.9185999631881714\n",
      "[Epoch 141] Score: 0.917199969291687\n",
      "[Epoch 142] Score: 0.9150999784469604\n",
      "[Epoch 143] Score: 0.9217000007629395\n",
      "[Epoch 144] Score: 0.9179999828338623\n",
      "[Epoch 145] Score: 0.915399968624115\n",
      "[Epoch 146] Score: 0.9162999987602234\n",
      "[Epoch 147] Score: 0.9152999520301819\n",
      "[Epoch 148] Score: 0.9157999753952026\n",
      "[Epoch 149] Score: 0.9164999723434448\n",
      "[Epoch 150] Score: 0.9146999716758728\n",
      "[Epoch 151] Score: 0.9157999753952026\n",
      "[Epoch 152] Score: 0.9161999821662903\n",
      "[Epoch 153] Score: 0.9145999550819397\n",
      "[Epoch 154] Score: 0.916700005531311\n",
      "[Epoch 155] Score: 0.9178999662399292\n",
      "[Epoch 156] Score: 0.917199969291687\n",
      "[Epoch 157] Score: 0.9181999564170837\n",
      "[Epoch 158] Score: 0.9161999821662903\n",
      "[Epoch 159] Score: 0.9151999950408936\n",
      "[Epoch 160] Score: 0.9169999957084656\n",
      "[Epoch 161] Score: 0.9190999865531921\n",
      "[Epoch 162] Score: 0.9190999865531921\n",
      "[Epoch 163] Score: 0.9197999835014343\n",
      "[Epoch 164] Score: 0.9156999588012695\n",
      "[Epoch 165] Score: 0.9169999957084656\n",
      "[Epoch 166] Score: 0.917199969291687\n",
      "[Epoch 167] Score: 0.9188999533653259\n",
      "[Epoch 168] Score: 0.9154999852180481\n",
      "[Epoch 169] Score: 0.9163999557495117\n",
      "[Epoch 170] Score: 0.9158999919891357\n",
      "[Epoch 171] Score: 0.9197999835014343\n",
      "[Epoch 172] Score: 0.9165999889373779\n",
      "[Epoch 173] Score: 0.916700005531311\n",
      "[Epoch 174] Score: 0.9174000024795532\n",
      "[Epoch 175] Score: 0.9176999926567078\n",
      "[Epoch 176] Score: 0.917199969291687\n",
      "[Epoch 177] Score: 0.91839998960495\n",
      "[Epoch 178] Score: 0.9150999784469604\n",
      "[Epoch 179] Score: 0.9179999828338623\n",
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.05\n",
      "\tbs: 16000\n",
      "[UPDATE] Running loss on train set... 0.006350617771148682 (acc: 0.9993599653244019 )\n",
      "[Epoch 180] Score: 0.9159999489784241\n",
      "[Epoch 181] Score: 0.9163999557495117\n",
      "[Epoch 182] Score: 0.9179999828338623\n",
      "[Epoch 183] Score: 0.9215999841690063\n",
      "[Epoch 184] Score: 0.9162999987602234\n",
      "[Epoch 185] Score: 0.9176999926567078\n",
      "[Epoch 186] Score: 0.91839998960495\n",
      "[Epoch 187] Score: 0.9172999858856201\n",
      "[Epoch 188] Score: 0.920199990272522\n",
      "[Epoch 189] Score: 0.9175999760627747\n",
      "[Epoch 190] Score: 0.9218999743461609\n",
      "[Epoch 191] Score: 0.9188999533653259\n",
      "[Epoch 192] Score: 0.9196999669075012\n",
      "[Epoch 193] Score: 0.9187999963760376\n",
      "[Epoch 194] Score: 0.9210999608039856\n",
      "[Epoch 195] Score: 0.9185000061988831\n",
      "[Epoch 196] Score: 0.9202999472618103\n",
      "[Epoch 197] Score: 0.9199999570846558\n",
      "[Epoch 198] Score: 0.9157999753952026\n",
      "[Epoch 199] Score: 0.9185999631881714\n"
     ]
    }
   ],
   "source": [
    "# ie \"Update LR to 0.02 and bs t0 640 on 60th epoch\"\n",
    "exp1_epochs = [0, 60, 120, 180]\n",
    "exp1_lr = [0.05, 0.05, 0.05, 0.05]\n",
    "exp1_bs = [128, 640, 3200, 16000]\n",
    "model = DaskClassifierExpiriments(**args)\n",
    "# train\n",
    "hist = train(model, \n",
    "             train_set, \n",
    "             test_set, \n",
    "             n_epochs=200, \n",
    "             epoch_sched=exp1_epochs, \n",
    "             lr_sched=exp1_lr, \n",
    "             bs_sched=exp1_bs, \n",
    "             log_interval=20,\n",
    "             exp='increasing-bs'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_stats(hist, 'increasing-bs', 'final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.05\n",
      "\tbs: 128\n",
      "[Epoch 0] Score: 0.6014999747276306\n",
      "[Epoch 1] Score: 0.6804999709129333\n",
      "[Epoch 2] Score: 0.7328000068664551\n",
      "[Epoch 3] Score: 0.7621999979019165\n",
      "[Epoch 4] Score: 0.7834999561309814\n",
      "[Epoch 5] Score: 0.8009999990463257\n",
      "[Epoch 6] Score: 0.8064000010490417\n",
      "[Epoch 7] Score: 0.8100000023841858\n",
      "[Epoch 8] Score: 0.8197999596595764\n",
      "[Epoch 9] Score: 0.812999963760376\n",
      "[Epoch 10] Score: 0.8154999613761902\n",
      "[TEST] Testing accuracy for 10th epoch is over 70%\n",
      "[TEST] Test passed with 0.8159999847412109 accuracy\n",
      "[Epoch 11] Score: 0.8373000025749207\n",
      "[Epoch 12] Score: 0.8402000069618225\n",
      "[Epoch 13] Score: 0.8319000005722046\n",
      "[Epoch 14] Score: 0.8525999784469604\n",
      "[Epoch 15] Score: 0.8307999968528748\n",
      "[Epoch 16] Score: 0.8412999510765076\n",
      "[Epoch 17] Score: 0.838699996471405\n",
      "[Epoch 18] Score: 0.837399959564209\n",
      "[Epoch 19] Score: 0.8515999913215637\n",
      "[Epoch 20] Score: 0.84579998254776\n",
      "[Epoch 21] Score: 0.8432999849319458\n",
      "[Epoch 22] Score: 0.8391000032424927\n",
      "[Epoch 23] Score: 0.8495999574661255\n",
      "[Epoch 24] Score: 0.8406999707221985\n",
      "[Epoch 25] Score: 0.8522999882698059\n",
      "[Epoch 26] Score: 0.8607999682426453\n",
      "[Epoch 27] Score: 0.8484999537467957\n",
      "[Epoch 28] Score: 0.8646999597549438\n",
      "[Epoch 29] Score: 0.8477999567985535\n",
      "[Epoch 30] Score: 0.863599956035614\n",
      "[Epoch 31] Score: 0.8549999594688416\n",
      "[Epoch 32] Score: 0.8503999710083008\n",
      "[Epoch 33] Score: 0.8657000064849854\n",
      "[Epoch 34] Score: 0.8601999878883362\n",
      "[Epoch 35] Score: 0.8550999760627747\n",
      "[Epoch 36] Score: 0.8613999485969543\n",
      "[Epoch 37] Score: 0.8641999959945679\n",
      "[Epoch 38] Score: 0.8509999513626099\n",
      "[Epoch 39] Score: 0.8641999959945679\n",
      "[Epoch 40] Score: 0.866599977016449\n",
      "[Epoch 41] Score: 0.8673999905586243\n",
      "[Epoch 42] Score: 0.8738999962806702\n",
      "[Epoch 43] Score: 0.8549999594688416\n",
      "[Epoch 44] Score: 0.8502999544143677\n",
      "[Epoch 45] Score: 0.859499990940094\n",
      "[Epoch 46] Score: 0.865399956703186\n",
      "[Epoch 47] Score: 0.8562999963760376\n",
      "[Epoch 48] Score: 0.8592999577522278\n",
      "[Epoch 49] Score: 0.8587999939918518\n",
      "[Epoch 50] Score: 0.8563999533653259\n",
      "[Epoch 51] Score: 0.8603000044822693\n",
      "[Epoch 52] Score: 0.864799976348877\n",
      "[Epoch 53] Score: 0.8615999817848206\n",
      "[Epoch 54] Score: 0.8690999746322632\n",
      "[Epoch 55] Score: 0.8400999903678894\n",
      "[Epoch 56] Score: 0.8662999868392944\n",
      "[Epoch 57] Score: 0.8707000017166138\n",
      "[Epoch 58] Score: 0.8641999959945679\n",
      "[Epoch 59] Score: 0.8482999801635742\n",
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.05\n",
      "\tbs: 640\n",
      "[UPDATE] Running loss on train set... 0.2726900820922852 (acc: 0.9056199789047241 )\n",
      "[Epoch 60] Score: 0.901699960231781\n",
      "[Epoch 61] Score: 0.9027999639511108\n",
      "[Epoch 62] Score: 0.9074999690055847\n",
      "[Epoch 63] Score: 0.9059000015258789\n",
      "[Epoch 64] Score: 0.9060999751091003\n",
      "[Epoch 65] Score: 0.9055999517440796\n",
      "[Epoch 66] Score: 0.9086999893188477\n",
      "[Epoch 67] Score: 0.9048999547958374\n",
      "[Epoch 68] Score: 0.9124999642372131\n",
      "[Epoch 69] Score: 0.9042999744415283\n",
      "[Epoch 70] Score: 0.9073999524116516\n",
      "[Epoch 71] Score: 0.8991999626159668\n",
      "[Epoch 72] Score: 0.9063999652862549\n",
      "[Epoch 73] Score: 0.9013999700546265\n",
      "[Epoch 74] Score: 0.9081999659538269\n",
      "[Epoch 75] Score: 0.9088000059127808\n",
      "[Epoch 76] Score: 0.9041000008583069\n",
      "[Epoch 77] Score: 0.9057999849319458\n",
      "[Epoch 78] Score: 0.901699960231781\n",
      "[Epoch 79] Score: 0.9099999666213989\n",
      "[Epoch 80] Score: 0.9004999995231628\n",
      "[Epoch 81] Score: 0.8930000066757202\n",
      "[Epoch 82] Score: 0.9052000045776367\n",
      "[Epoch 83] Score: 0.8996999859809875\n",
      "[Epoch 84] Score: 0.9061999917030334\n",
      "[Epoch 85] Score: 0.9017999768257141\n",
      "[Epoch 86] Score: 0.9009000062942505\n",
      "[Epoch 87] Score: 0.9030999541282654\n",
      "[Epoch 88] Score: 0.9032999873161316\n",
      "[Epoch 89] Score: 0.9081999659538269\n",
      "[Epoch 90] Score: 0.9062999486923218\n",
      "[Epoch 91] Score: 0.9016000032424927\n",
      "[Epoch 92] Score: 0.9048999547958374\n",
      "[Epoch 93] Score: 0.9065999984741211\n",
      "[Epoch 94] Score: 0.8951999545097351\n",
      "[Epoch 95] Score: 0.9009000062942505\n",
      "[Epoch 96] Score: 0.901699960231781\n",
      "[Epoch 97] Score: 0.9037999510765076\n",
      "[Epoch 98] Score: 0.9006999731063843\n",
      "[Epoch 99] Score: 0.8992999792098999\n",
      "[Epoch 100] Score: 0.9037999510765076\n",
      "[Epoch 101] Score: 0.9002999663352966\n",
      "[Epoch 102] Score: 0.9006999731063843\n",
      "[Epoch 103] Score: 0.8987999558448792\n",
      "[Epoch 104] Score: 0.9032999873161316\n",
      "[Epoch 105] Score: 0.8967999815940857\n",
      "[Epoch 106] Score: 0.9002999663352966\n",
      "[Epoch 107] Score: 0.9052000045776367\n",
      "[Epoch 108] Score: 0.9013999700546265\n",
      "[Epoch 109] Score: 0.8917999863624573\n",
      "[Epoch 110] Score: 0.8944999575614929\n",
      "[Epoch 111] Score: 0.902899980545044\n",
      "[Epoch 112] Score: 0.9027999639511108\n",
      "[Epoch 113] Score: 0.8976999521255493\n",
      "[Epoch 114] Score: 0.901199996471405\n",
      "[Epoch 115] Score: 0.8991999626159668\n",
      "[Epoch 116] Score: 0.9024999737739563\n",
      "[Epoch 117] Score: 0.9021999835968018\n",
      "[Epoch 118] Score: 0.9016000032424927\n",
      "[Epoch 119] Score: 0.903499960899353\n",
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.01\n",
      "\tbs: 640\n",
      "[UPDATE] Running loss on train set... 0.058935361862182616 (acc: 0.981939971446991 )\n",
      "[Epoch 120] Score: 0.9154999852180481\n",
      "[Epoch 121] Score: 0.9190999865531921\n",
      "[Epoch 122] Score: 0.9192999601364136\n",
      "[Epoch 123] Score: 0.9199000000953674\n",
      "[Epoch 124] Score: 0.9176999926567078\n",
      "[Epoch 125] Score: 0.9220999479293823\n",
      "[Epoch 126] Score: 0.9193999767303467\n",
      "[Epoch 127] Score: 0.9203999638557434\n",
      "[Epoch 128] Score: 0.9211999773979187\n",
      "[Epoch 129] Score: 0.9196999669075012\n",
      "[Epoch 130] Score: 0.9223999977111816\n",
      "[Epoch 131] Score: 0.9214999675750732\n",
      "[Epoch 132] Score: 0.9210000038146973\n",
      "[Epoch 133] Score: 0.92249995470047\n",
      "[Epoch 134] Score: 0.9246999621391296\n",
      "[Epoch 135] Score: 0.9187999963760376\n",
      "[Epoch 136] Score: 0.9222999811172485\n",
      "[Epoch 137] Score: 0.9221999645233154\n",
      "[Epoch 138] Score: 0.9202999472618103\n",
      "[Epoch 139] Score: 0.9225999712944031\n",
      "[Epoch 140] Score: 0.9193999767303467\n",
      "[Epoch 141] Score: 0.9194999933242798\n",
      "[Epoch 142] Score: 0.9204999804496765\n",
      "[Epoch 143] Score: 0.9205999970436096\n",
      "[Epoch 144] Score: 0.9210000038146973\n",
      "[Epoch 145] Score: 0.9205999970436096\n",
      "[Epoch 146] Score: 0.9196999669075012\n",
      "[Epoch 147] Score: 0.9218999743461609\n",
      "[Epoch 148] Score: 0.9221999645233154\n",
      "[Epoch 149] Score: 0.9215999841690063\n",
      "[Epoch 150] Score: 0.9228999614715576\n",
      "[Epoch 151] Score: 0.9217000007629395\n",
      "[Epoch 152] Score: 0.9258999824523926\n",
      "[Epoch 153] Score: 0.9232999682426453\n",
      "[Epoch 154] Score: 0.9232999682426453\n",
      "[Epoch 155] Score: 0.9240999817848206\n",
      "[Epoch 156] Score: 0.9253999590873718\n",
      "[Epoch 157] Score: 0.9210999608039856\n",
      "[Epoch 158] Score: 0.9239999651908875\n",
      "[Epoch 159] Score: 0.9196999669075012\n",
      "[Epoch 160] Score: 0.9235000014305115\n",
      "[Epoch 161] Score: 0.921999990940094\n",
      "[Epoch 162] Score: 0.9185000061988831\n",
      "[Epoch 163] Score: 0.9223999977111816\n",
      "[Epoch 164] Score: 0.9197999835014343\n",
      "[Epoch 165] Score: 0.9203999638557434\n",
      "[Epoch 166] Score: 0.9232999682426453\n",
      "[Epoch 167] Score: 0.9203999638557434\n",
      "[Epoch 168] Score: 0.9228000044822693\n",
      "[Epoch 169] Score: 0.9225999712944031\n",
      "[Epoch 170] Score: 0.9194999933242798\n",
      "[Epoch 171] Score: 0.9249999523162842\n",
      "[Epoch 172] Score: 0.923799991607666\n",
      "[Epoch 173] Score: 0.9236999750137329\n",
      "[Epoch 174] Score: 0.9225999712944031\n",
      "[Epoch 175] Score: 0.9235999584197998\n",
      "[Epoch 176] Score: 0.924299955368042\n",
      "[Epoch 177] Score: 0.9210000038146973\n",
      "[Epoch 178] Score: 0.9210999608039856\n",
      "[Epoch 179] Score: 0.9226999878883362\n",
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.002\n",
      "\tbs: 640\n",
      "[UPDATE] Running loss on train set... 0.006495870532989502 (acc: 0.9994199872016907 )\n",
      "[Epoch 180] Score: 0.9228000044822693\n",
      "[Epoch 181] Score: 0.923799991607666\n",
      "[Epoch 182] Score: 0.9258999824523926\n",
      "[Epoch 183] Score: 0.9253999590873718\n",
      "[Epoch 184] Score: 0.9238999485969543\n",
      "[Epoch 185] Score: 0.9247999787330627\n",
      "[Epoch 186] Score: 0.9246000051498413\n",
      "[Epoch 187] Score: 0.9228000044822693\n",
      "[Epoch 188] Score: 0.9213999509811401\n",
      "[Epoch 189] Score: 0.9229999780654907\n",
      "[Epoch 190] Score: 0.9185999631881714\n",
      "[Epoch 191] Score: 0.9249999523162842\n",
      "[Epoch 192] Score: 0.9217999577522278\n",
      "[Epoch 193] Score: 0.9231999516487122\n",
      "[Epoch 194] Score: 0.9249999523162842\n",
      "[Epoch 195] Score: 0.9229999780654907\n",
      "[Epoch 196] Score: 0.9246000051498413\n",
      "[Epoch 197] Score: 0.9229999780654907\n",
      "[Epoch 198] Score: 0.9247999787330627\n",
      "[Epoch 199] Score: 0.9213999509811401\n"
     ]
    }
   ],
   "source": [
    "# ie \"Update LR to 0.1 and bs t0 640 on 60th epoch\"\n",
    "exp2_epochs = [0, 60, 120, 180]\n",
    "exp2_lr = [0.05, \n",
    "           0.05, \n",
    "           0.05 / 5, \n",
    "           0.05 / 5 / 5\n",
    "          ]\n",
    "exp2_bs = [128, 640, 640, 640]\n",
    "model = DaskClassifierExpiriments(**args)\n",
    "# train\n",
    "hist = train(model, \n",
    "             train_set, \n",
    "             test_set, \n",
    "             n_epochs=200, \n",
    "             epoch_sched=exp2_epochs, \n",
    "             lr_sched=exp2_lr, \n",
    "             bs_sched=exp2_bs, \n",
    "             log_interval=20,\n",
    "             exp='hybrid'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_stats(hist, 'hybrid', 'final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.05\n",
      "\tbs: 128\n",
      "[Epoch 0] Score: 0.6290000081062317\n",
      "[Epoch 1] Score: 0.694599986076355\n",
      "[Epoch 2] Score: 0.7508999705314636\n",
      "[Epoch 3] Score: 0.7793999910354614\n",
      "[Epoch 4] Score: 0.8016999959945679\n",
      "[Epoch 5] Score: 0.8024999499320984\n",
      "[Epoch 6] Score: 0.8096999526023865\n",
      "[Epoch 7] Score: 0.832099974155426\n",
      "[Epoch 8] Score: 0.8307999968528748\n",
      "[Epoch 9] Score: 0.8369999527931213\n",
      "[Epoch 10] Score: 0.8292999863624573\n",
      "[TEST] Testing accuracy for 10th epoch is over 70%\n",
      "[TEST] Test passed with 0.8325999975204468 accuracy\n",
      "[Epoch 11] Score: 0.8430999517440796\n",
      "[Epoch 12] Score: 0.8443999886512756\n",
      "[Epoch 13] Score: 0.8333999514579773\n",
      "[Epoch 14] Score: 0.8466999530792236\n",
      "[Epoch 15] Score: 0.8345999717712402\n",
      "[Epoch 16] Score: 0.8388999700546265\n",
      "[Epoch 17] Score: 0.8547999858856201\n",
      "[Epoch 18] Score: 0.8427000045776367\n",
      "[Epoch 19] Score: 0.8279999494552612\n",
      "[Epoch 20] Score: 0.8407999873161316\n",
      "[Epoch 21] Score: 0.856499969959259\n",
      "[Epoch 22] Score: 0.8574000000953674\n",
      "[Epoch 23] Score: 0.851099967956543\n",
      "[Epoch 24] Score: 0.8496999740600586\n",
      "[Epoch 25] Score: 0.8600999712944031\n",
      "[Epoch 26] Score: 0.8515999913215637\n",
      "[Epoch 27] Score: 0.8587999939918518\n",
      "[Epoch 28] Score: 0.8527999520301819\n",
      "[Epoch 29] Score: 0.8495000004768372\n",
      "[Epoch 30] Score: 0.858299970626831\n",
      "[Epoch 31] Score: 0.856499969959259\n",
      "[Epoch 32] Score: 0.8600999712944031\n",
      "[Epoch 33] Score: 0.8534999489784241\n",
      "[Epoch 34] Score: 0.8618999719619751\n",
      "[Epoch 35] Score: 0.864799976348877\n",
      "[Epoch 36] Score: 0.8615999817848206\n",
      "[Epoch 37] Score: 0.8747999668121338\n",
      "[Epoch 38] Score: 0.8427000045776367\n",
      "[Epoch 39] Score: 0.8562999963760376\n",
      "[Epoch 40] Score: 0.8679999709129333\n",
      "[Epoch 41] Score: 0.85589998960495\n",
      "[Epoch 42] Score: 0.8671999573707581\n",
      "[Epoch 43] Score: 0.8702999949455261\n",
      "[Epoch 44] Score: 0.8553999662399292\n",
      "[Epoch 45] Score: 0.8554999828338623\n",
      "[Epoch 46] Score: 0.8590999841690063\n",
      "[Epoch 47] Score: 0.871399998664856\n",
      "[Epoch 48] Score: 0.849399983882904\n",
      "[Epoch 49] Score: 0.8624999523162842\n",
      "[Epoch 50] Score: 0.8588999509811401\n",
      "[Epoch 51] Score: 0.8615999817848206\n",
      "[Epoch 52] Score: 0.8643999695777893\n",
      "[Epoch 53] Score: 0.8610000014305115\n",
      "[Epoch 54] Score: 0.8536999821662903\n",
      "[Epoch 55] Score: 0.8579999804496765\n",
      "[Epoch 56] Score: 0.8661999702453613\n",
      "[Epoch 57] Score: 0.864799976348877\n",
      "[Epoch 58] Score: 0.8667999505996704\n",
      "[Epoch 59] Score: 0.8585999608039856\n",
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.05\n",
      "\tbs: 640\n",
      "[UPDATE] Running loss on train set... 0.2544114169311523 (acc: 0.9138000011444092 )\n",
      "[Epoch 60] Score: 0.899399995803833\n",
      "[Epoch 61] Score: 0.9059999585151672\n",
      "[Epoch 62] Score: 0.9023999571800232\n",
      "[Epoch 63] Score: 0.9053999781608582\n",
      "[Epoch 64] Score: 0.9077999591827393\n",
      "[Epoch 65] Score: 0.9030999541282654\n",
      "[Epoch 66] Score: 0.910099983215332\n",
      "[Epoch 67] Score: 0.9121999740600586\n",
      "[Epoch 68] Score: 0.9052000045776367\n",
      "[Epoch 69] Score: 0.9070999622344971\n",
      "[Epoch 70] Score: 0.9060999751091003\n",
      "[Epoch 71] Score: 0.9045999646186829\n",
      "[Epoch 72] Score: 0.9013999700546265\n",
      "[Epoch 73] Score: 0.9044999480247498\n",
      "[Epoch 74] Score: 0.9016000032424927\n",
      "[Epoch 75] Score: 0.9097999930381775\n",
      "[Epoch 76] Score: 0.9017999768257141\n",
      "[Epoch 77] Score: 0.8985999822616577\n",
      "[Epoch 78] Score: 0.8991000056266785\n",
      "[Epoch 79] Score: 0.9020999670028687\n",
      "[Epoch 80] Score: 0.894599974155426\n",
      "[Epoch 81] Score: 0.9018999934196472\n",
      "[Epoch 82] Score: 0.8995999693870544\n",
      "[Epoch 83] Score: 0.8907999992370605\n",
      "[Epoch 84] Score: 0.9053999781608582\n",
      "[Epoch 85] Score: 0.9016000032424927\n",
      "[Epoch 86] Score: 0.9024999737739563\n",
      "[Epoch 87] Score: 0.9102999567985535\n",
      "[Epoch 88] Score: 0.9042999744415283\n",
      "[Epoch 89] Score: 0.9021999835968018\n",
      "[Epoch 90] Score: 0.8976999521255493\n",
      "[Epoch 91] Score: 0.9054999947547913\n",
      "[Epoch 92] Score: 0.8964999914169312\n",
      "[Epoch 93] Score: 0.8994999527931213\n",
      "[Epoch 94] Score: 0.8988999724388123\n",
      "[Epoch 95] Score: 0.9048999547958374\n",
      "[Epoch 96] Score: 0.8995999693870544\n",
      "[Epoch 97] Score: 0.8962999582290649\n",
      "[Epoch 98] Score: 0.9041000008583069\n",
      "[Epoch 99] Score: 0.895799994468689\n",
      "[Epoch 100] Score: 0.899399995803833\n",
      "[Epoch 101] Score: 0.902999997138977\n",
      "[Epoch 102] Score: 0.8998000025749207\n",
      "[Epoch 103] Score: 0.9004999995231628\n",
      "[Epoch 104] Score: 0.9070000052452087\n",
      "[Epoch 105] Score: 0.8924999833106995\n",
      "[Epoch 106] Score: 0.898099958896637\n",
      "[Epoch 107] Score: 0.8995999693870544\n",
      "[Epoch 108] Score: 0.8991999626159668\n",
      "[Epoch 109] Score: 0.9049999713897705\n",
      "[Epoch 110] Score: 0.9047999978065491\n",
      "[Epoch 111] Score: 0.901199996471405\n",
      "[Epoch 112] Score: 0.899899959564209\n",
      "[Epoch 113] Score: 0.8974999785423279\n",
      "[Epoch 114] Score: 0.9063999652862549\n",
      "[Epoch 115] Score: 0.8823999762535095\n",
      "[Epoch 116] Score: 0.8974999785423279\n",
      "[Epoch 117] Score: 0.8946999907493591\n",
      "[Epoch 118] Score: 0.9063999652862549\n",
      "[Epoch 119] Score: 0.8980000019073486\n",
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.05\n",
      "\tbs: 3200\n",
      "[UPDATE] Running loss on train set... 0.07174774230957032 (acc: 0.9771599769592285 )\n",
      "[Epoch 120] Score: 0.9140999913215637\n",
      "[Epoch 121] Score: 0.9178999662399292\n",
      "[Epoch 122] Score: 0.9192000031471252\n",
      "[Epoch 123] Score: 0.920199990272522\n",
      "[Epoch 124] Score: 0.9193999767303467\n",
      "[Epoch 125] Score: 0.9228999614715576\n",
      "[Epoch 126] Score: 0.9204999804496765\n",
      "[Epoch 127] Score: 0.9182999730110168\n",
      "[Epoch 128] Score: 0.9232999682426453\n",
      "[Epoch 129] Score: 0.9232999682426453\n",
      "[Epoch 130] Score: 0.9253999590873718\n",
      "[Epoch 131] Score: 0.9200999736785889\n",
      "[Epoch 132] Score: 0.9228999614715576\n",
      "[Epoch 133] Score: 0.9228000044822693\n",
      "[Epoch 134] Score: 0.9218999743461609\n",
      "[Epoch 135] Score: 0.9231999516487122\n",
      "[Epoch 136] Score: 0.920199990272522\n",
      "[Epoch 137] Score: 0.9221999645233154\n",
      "[Epoch 138] Score: 0.9199000000953674\n",
      "[Epoch 139] Score: 0.9181999564170837\n",
      "[Epoch 140] Score: 0.9182999730110168\n",
      "[Epoch 141] Score: 0.9215999841690063\n",
      "[Epoch 142] Score: 0.9193999767303467\n",
      "[Epoch 143] Score: 0.9203999638557434\n",
      "[Epoch 144] Score: 0.918999969959259\n",
      "[Epoch 145] Score: 0.920699954032898\n",
      "[Epoch 146] Score: 0.920199990272522\n",
      "[Epoch 147] Score: 0.9212999939918518\n",
      "[Epoch 148] Score: 0.9228000044822693\n",
      "[Epoch 149] Score: 0.9197999835014343\n",
      "[Epoch 150] Score: 0.9229999780654907\n",
      "[Epoch 151] Score: 0.9232999682426453\n",
      "[Epoch 152] Score: 0.9229999780654907\n",
      "[Epoch 153] Score: 0.9197999835014343\n",
      "[Epoch 154] Score: 0.9217999577522278\n",
      "[Epoch 155] Score: 0.9199999570846558\n",
      "[Epoch 156] Score: 0.9248999953269958\n",
      "[Epoch 157] Score: 0.9217000007629395\n",
      "[Epoch 158] Score: 0.923799991607666\n",
      "[Epoch 159] Score: 0.9235999584197998\n",
      "[Epoch 160] Score: 0.920699954032898\n",
      "[Epoch 161] Score: 0.920199990272522\n",
      "[Epoch 162] Score: 0.9163999557495117\n",
      "[Epoch 163] Score: 0.9202999472618103\n",
      "[Epoch 164] Score: 0.9211999773979187\n",
      "[Epoch 165] Score: 0.9212999939918518\n",
      "[Epoch 166] Score: 0.9222999811172485\n",
      "[Epoch 167] Score: 0.9233999848365784\n",
      "[Epoch 168] Score: 0.9248999953269958\n",
      "[Epoch 169] Score: 0.9230999946594238\n",
      "[Epoch 170] Score: 0.921999990940094\n",
      "[Epoch 171] Score: 0.918999969959259\n",
      "[Epoch 172] Score: 0.9223999977111816\n",
      "[Epoch 173] Score: 0.9199999570846558\n",
      "[Epoch 174] Score: 0.9211999773979187\n",
      "[Epoch 175] Score: 0.9273999929428101\n",
      "[Epoch 176] Score: 0.9214999675750732\n",
      "[Epoch 177] Score: 0.9230999946594238\n",
      "[Epoch 178] Score: 0.9240999817848206\n",
      "[Epoch 179] Score: 0.9249999523162842\n",
      "[UPDATE] Updated model params:\n",
      "\tlr: 0.01\n",
      "\tbs: 3200\n",
      "[UPDATE] Running loss on train set... 0.00651513126373291 (acc: 0.9992799758911133 )\n",
      "[Epoch 180] Score: 0.9248999953269958\n",
      "[Epoch 181] Score: 0.9256999492645264\n",
      "[Epoch 182] Score: 0.925599992275238\n",
      "[Epoch 183] Score: 0.9241999983787537\n",
      "[Epoch 184] Score: 0.9248999953269958\n",
      "[Epoch 185] Score: 0.925599992275238\n",
      "[Epoch 186] Score: 0.9229999780654907\n",
      "[Epoch 187] Score: 0.9228999614715576\n",
      "[Epoch 188] Score: 0.9253000020980835\n",
      "[Epoch 189] Score: 0.9230999946594238\n",
      "[Epoch 190] Score: 0.9238999485969543\n",
      "[Epoch 191] Score: 0.9231999516487122\n",
      "[Epoch 192] Score: 0.9215999841690063\n",
      "[Epoch 193] Score: 0.9236999750137329\n",
      "[Epoch 194] Score: 0.9239999651908875\n",
      "[Epoch 195] Score: 0.9235999584197998\n",
      "[Epoch 196] Score: 0.921999990940094\n",
      "[Epoch 197] Score: 0.9235999584197998\n",
      "[Epoch 198] Score: 0.9254999756813049\n",
      "[Epoch 199] Score: 0.925599992275238\n"
     ]
    }
   ],
   "source": [
    "# ie \"Update ...\"\n",
    "exp3_epochs = [0, 60, 120, 180]\n",
    "exp3_lr = [0.05, \n",
    "           0.05, \n",
    "           0.05, \n",
    "           0.05 / 5\n",
    "          ]\n",
    "exp3_bs = [128, 640, 3200, 3200]\n",
    "model = DaskClassifierExpiriments(**args)\n",
    "# train\n",
    "hist = train(model, \n",
    "             train_set, \n",
    "             test_set, \n",
    "             n_epochs=200, \n",
    "             epoch_sched=exp3_epochs, \n",
    "             lr_sched=exp3_lr, \n",
    "             bs_sched=exp3_bs, \n",
    "             log_interval=20,\n",
    "             exp='hybrid-2'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_stats(hist, 'hybrid-2', 'final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adadamp",
   "language": "python",
   "name": "adadamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
