{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Wide ResNet with Dask Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/ubuntu/adadamp-experiments')\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "from adadamp.adadamp import DaskClassifier, DaskClassifierIncreasingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://172.31.40.124/24831/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.31.40.124:8787/status' target='_blank'>http://172.31.40.124:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.48 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://172.31.40.124/24831/1' processes=1 threads=4, memory=16.48 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training client\n",
    "from dask.distributed import Client\n",
    "\n",
    "def _prep():\n",
    "    from distributed.protocol import torch\n",
    "\n",
    "client = Client(processes=False)\n",
    "client.run(_prep)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Wide_ResNet\n",
    "\n",
    "client.upload_file(\"./exp-dask/model.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load data - https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./exp-dask/data', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./exp-dask/data', train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for expiriment 1: \n",
    "#    “Decaying learning rate” follows the original implementation; \n",
    "#     the batch size is constant, while the learning rate repeatedly \n",
    "#     decays by a factor of 5 at a sequence of steps\n",
    "# my understanding is that this is the \"control\" expeririment, where we are not touching the number of \n",
    "# workers nor the batch size\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "model = DaskClassifierIncreasingLR(\n",
    "    module=Wide_ResNet,\n",
    "    module__depth=16,\n",
    "    module__widen_factor=4,\n",
    "    module__dropout_rate=0.3,\n",
    "    module__num_classes=len(classes),\n",
    "    loss=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer__lr=0.1,\n",
    "    optimizer__momentum=0.9,\n",
    "    optimizer__nesterov=True,\n",
    "    optimizer__weight_decay=0.5e-3,\n",
    "    batch_size=128,\n",
    "    max_epochs=200,\n",
    "    device=device,\n",
    "    grads_per_worker=128,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Wide-Resnet 16x4\n",
      "Initial Learning Rate: 0.1\n",
      "Epoch: 1 (acc: 0.09953999519348145)\n",
      "Epoch: 2 (acc: 0.09959999471902847)\n",
      "Epoch: 3 (acc: 0.09953999519348145)\n",
      "Epoch: 4 (acc: 0.09963999688625336)\n",
      "Epoch: 5 (acc: 0.09963999688625336)\n",
      "Epoch: 6 (acc: 0.09978000074625015)\n",
      "Epoch: 7 (acc: 0.09971999377012253)\n",
      "Epoch: 8 (acc: 0.09933999925851822)\n",
      "Epoch: 9 (acc: 0.09947999566793442)\n",
      "Epoch: 10 (acc: 0.09953999519348145)\n",
      "Epoch: 11 (acc: 0.09950000047683716)\n",
      "Epoch: 12 (acc: 0.09947999566793442)\n",
      "Epoch: 13 (acc: 0.09939999878406525)\n",
      "Epoch: 14 (acc: 0.09961999952793121)\n",
      "Epoch: 15 (acc: 0.09961999952793121)\n",
      "Epoch: 16 (acc: 0.09941999614238739)\n",
      "Epoch: 17 (acc: 0.09957999736070633)\n",
      "Epoch: 18 (acc: 0.09963999688625336)\n",
      "Epoch: 19 (acc: 0.09950000047683716)\n",
      "Epoch: 20 (acc: 0.09950000047683716)\n",
      "Epoch: 21 (acc: 0.09963999688625336)\n",
      "Epoch: 22 (acc: 0.09973999857902527)\n",
      "Epoch: 23 (acc: 0.09969999641180038)\n",
      "Epoch: 24 (acc: 0.09959999471902847)\n",
      "Epoch: 25 (acc: 0.09953999519348145)\n",
      "Epoch: 26 (acc: 0.09953999519348145)\n",
      "Epoch: 27 (acc: 0.0993799939751625)\n",
      "Epoch: 28 (acc: 0.0995199978351593)\n",
      "Epoch: 29 (acc: 0.09989999979734421)\n",
      "Epoch: 30 (acc: 0.0993799939751625)\n",
      "Epoch: 31 (acc: 0.09953999519348145)\n",
      "Epoch: 32 (acc: 0.09957999736070633)\n",
      "Epoch: 33 (acc: 0.09971999377012253)\n",
      "Epoch: 34 (acc: 0.09959999471902847)\n",
      "Epoch: 35 (acc: 0.09971999377012253)\n",
      "Epoch: 36 (acc: 0.09975999593734741)\n",
      "Epoch: 37 (acc: 0.09933999925851822)\n",
      "Epoch: 38 (acc: 0.0997999981045723)\n",
      "Epoch: 39 (acc: 0.09945999830961227)\n",
      "Epoch: 40 (acc: 0.09941999614238739)\n",
      "Epoch: 41 (acc: 0.09971999377012253)\n",
      "Epoch: 42 (acc: 0.0993799939751625)\n",
      "Epoch: 43 (acc: 0.09957999736070633)\n",
      "Epoch: 44 (acc: 0.0995199978351593)\n",
      "Epoch: 45 (acc: 0.0996599942445755)\n",
      "Epoch: 46 (acc: 0.09953999519348145)\n",
      "Epoch: 47 (acc: 0.09975999593734741)\n",
      "Epoch: 48 (acc: 0.09959999471902847)\n",
      "Epoch: 49 (acc: 0.09957999736070633)\n",
      "Epoch: 50 (acc: 0.09969999641180038)\n",
      "Epoch: 51 (acc: 0.0996599942445755)\n",
      "Epoch: 52 (acc: 0.0996599942445755)\n",
      "Epoch: 53 (acc: 0.09969999641180038)\n",
      "Epoch: 54 (acc: 0.0996599942445755)\n",
      "Epoch: 55 (acc: 0.0996599942445755)\n",
      "Epoch: 56 (acc: 0.09957999736070633)\n",
      "Epoch: 57 (acc: 0.09947999566793442)\n",
      "Epoch: 58 (acc: 0.09969999641180038)\n",
      "Epoch: 59 (acc: 0.09956000000238419)\n",
      "Updated Learning Rate: 0.02\n",
      "Epoch: 60 (acc: 0.09945999830961227)\n",
      "Epoch: 61 (acc: 0.09973999857902527)\n",
      "Epoch: 62 (acc: 0.09959999471902847)\n",
      "Epoch: 63 (acc: 0.09953999519348145)\n",
      "Epoch: 64 (acc: 0.09959999471902847)\n",
      "Epoch: 65 (acc: 0.09944000095129013)\n",
      "Epoch: 66 (acc: 0.09969999641180038)\n",
      "Epoch: 67 (acc: 0.09957999736070633)\n",
      "Epoch: 68 (acc: 0.09925999492406845)\n",
      "Epoch: 69 (acc: 0.09947999566793442)\n",
      "Epoch: 70 (acc: 0.09969999641180038)\n",
      "Epoch: 71 (acc: 0.09953999519348145)\n",
      "Epoch: 72 (acc: 0.09957999736070633)\n"
     ]
    }
   ],
   "source": [
    "args = (model, train_set, test_set)\n",
    "_, test_y = test_sest # todo: passs tests sest for training\n",
    "model.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toCSV = model.curr_metas\n",
    "with open('./exp-dask/exp1-decreaseingLR-const-workers-v0.csv', 'w', encoding='utf8', newline='') as output_file:\n",
    "    fc = csv.DictWriter(output_file, fieldnames=toCSV[0].keys())\n",
    "    fc.writeheader()\n",
    "    fc.writerows(toCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_latest_p37)",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
