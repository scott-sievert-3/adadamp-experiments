{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Wide ResNet with Dask Classifier\n",
    "\n",
    "Training notebook for various training runs on DaskClassifier with a WideResnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib  \n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "from copy import copy\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import simulator\n",
    "classifier = importlib.import_module(\"exp-dask.classifier\")\n",
    "from classifier import DaskClassifierExpiriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://172.31.40.124/27181/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://172.31.40.124:8787/status' target='_blank'>http://172.31.40.124:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>4</li>\n",
       "  <li><b>Memory: </b>16.48 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://172.31.40.124/27181/1' processes=1 threads=4, memory=16.48 GB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model\n",
    "def _prep():\n",
    "    from distributed.protocol import torch\n",
    "\n",
    "client = Client(processes=False)\n",
    "client.run(_prep)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Wide_ResNet\n",
    "client.upload_file(\"./exp-dask/model.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# set up data\n",
    "train_set = torchvision.datasets.CIFAR10(root='./exp-dask/data', train=True, download=True, transform=transform_train)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./exp-dask/data', train=False, download=True, transform=transform_test)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stats(hist, exp, epoch):\n",
    "    toCSV = hist\n",
    "    with open('./exp-dask/stats/{}/exp-{}.csv'.format(exp, epoch), 'w', encoding='utf8', newline='') as output_file:\n",
    "        fc = csv.DictWriter(output_file, fieldnames=toCSV[0].keys())\n",
    "        fc.writeheader()\n",
    "        fc.writerows(toCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, model, test_set):\n",
    "    \"\"\"\n",
    "    tests if model meets certain testing standards:\n",
    "    - by 10th epoch, accuracy is over 70%\n",
    "    \"\"\"\n",
    "    if epoch == 10:\n",
    "        print(\"[TEST] Testing accuracy for 10th epoch is over 70%\")\n",
    "        score = model.score(test_set)\n",
    "        acc = model._meta['score__acc']\n",
    "        if acc < 0.70:\n",
    "            print(\"[TEST] Test failed with {} accuracy\".format(acc))\n",
    "            return False\n",
    "        else:\n",
    "            print(\"[TEST] Test passed with {} accuracy\".format(acc))\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_set, test_set, n_epochs=200, dampings=None, log_interval=1, exp='increasing-bs'):\n",
    "    \"\"\"\n",
    "    Train based on expiriment params\n",
    "    \n",
    "    Parameters:\n",
    "    epoch_sched: update lr and bs at epochs in this list\n",
    "    lr_sched: update lr to value at matching epoch. Should be same length as epoch_sched\n",
    "    bs_sched: update bs to value at matching epoch. Should be same length as epoch_sched\n",
    "    \"\"\"\n",
    "    \n",
    "    history = []\n",
    "    for epoch in range(n_epochs):\n",
    "        # check for updates\n",
    "        bs = dampings.get(epoch, None)\n",
    "        if bs:\n",
    "            model.damping_ = bs\n",
    "            print(\"[UPDATE] Updated model params\")\n",
    "            if epoch != 0:\n",
    "                print(\"[UPDATE] Running loss on train set...\", end=\" \")\n",
    "                train_score = model.score(train_set)\n",
    "                print(model._meta['score__loss'], '(acc:', model._meta['score__acc'], ')')\n",
    "        # run\n",
    "        print(\"[Epoch {}]\".format(epoch), end=\"\")\n",
    "        model.partial_fit(train_set)\n",
    "        score = model.score(test_set)\n",
    "        datum = {\"epoch\": epoch, \"score\": score, **model.get_params(), **model.meta_}\n",
    "        print(\" Score: {}\".format(score))\n",
    "        history.append(datum)\n",
    "        \n",
    "        # test\n",
    "        if test(epoch, model, test_set) == False:\n",
    "            print(\"[TEST] Test failed, exiting\")\n",
    "            break\n",
    "        \n",
    "        if epoch % log_interval == 0:\n",
    "            write_stats(history, exp, 'ep{}'.format(epoch))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Const Batch Size (512), decreasing LR\n",
    "\n",
    "# lr and bs\n",
    "orig_lr = 0.05\n",
    "orig_bs = 512\n",
    "# exp\n",
    "exp_lr = orig_lr\n",
    "exp_bs = orig_bs\n",
    "exp_momentum = 0.9\n",
    "# damping sched\n",
    "dampings = {\n",
    "    0:   exp_bs,\n",
    "    60:  exp_bs * 5,\n",
    "    120: exp_bs * 5 * 5,\n",
    "    180: exp_bs * 5 * 5 * 5,\n",
    "}\n",
    "\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "args = dict(\n",
    "    module=Wide_ResNet,\n",
    "    module__depth=16,\n",
    "    module__widen_factor=4,\n",
    "    module__dropout_rate=0.3,\n",
    "    module__num_classes=len(classes),\n",
    "    loss=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer__lr=exp_lr,\n",
    "    optimizer__momentum=exp_momentum,\n",
    "    optimizer__nesterov=True,\n",
    "    optimizer__weight_decay=0.5e-3,\n",
    "    max_epochs=200,\n",
    "    device=device,\n",
    "    grads_per_worker=128,\n",
    "    client=client,\n",
    "    max_batch_size=512,\n",
    "    lr=exp_lr,\n",
    "    batch_size=exp_bs\n",
    ")\n",
    "# set up\n",
    "model = DaskClassifierExpiriments(**args)\n",
    "# train\n",
    "hist = None\n",
    "with performance_report(filename=\"dask-report.html\"):\n",
    "    hist = train(model, \n",
    "             train_set, \n",
    "             test_set, \n",
    "             n_epochs=200, \n",
    "             dampings=dampings, \n",
    "             log_interval=20,\n",
    "             exp='dec-lr-512bs'\n",
    "            )\n",
    "write_stats(hist, 'dec-lr-512bs', 'final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256 initial batch size, max BS 5120\n",
    "\n",
    "# lr and bs\n",
    "orig_lr = 0.05\n",
    "orig_bs = 128\n",
    "# exp\n",
    "exp_lr = orig_lr * 2\n",
    "exp_bs = orig_bs * 2\n",
    "exp_momentum = 0.9\n",
    "# damping sched\n",
    "dampings = {\n",
    "    0:   exp_bs,\n",
    "    60:  exp_bs * 5,\n",
    "    120: exp_bs * 5 * 5,\n",
    "    180: exp_bs * 5 * 5 * 5,\n",
    "}\n",
    "\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "args = dict(\n",
    "    module=Wide_ResNet,\n",
    "    module__depth=16,\n",
    "    module__widen_factor=4,\n",
    "    module__dropout_rate=0.3,\n",
    "    module__num_classes=len(classes),\n",
    "    loss=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer__lr=exp_lr,\n",
    "    optimizer__momentum=exp_momentum,\n",
    "    optimizer__nesterov=True,\n",
    "    optimizer__weight_decay=0.5e-3,\n",
    "    max_epochs=200,\n",
    "    device=device,\n",
    "    grads_per_worker=128,\n",
    "    client=client,\n",
    "    max_batch_size=5120,\n",
    "    lr=exp_lr,\n",
    "    batch_size=exp_bs\n",
    ")\n",
    "# set up\n",
    "model = DaskClassifierExpiriments(**args)\n",
    "# train\n",
    "hist = None\n",
    "with performance_report(filename=\"dask-report.html\"):\n",
    "    hist = train(model, \n",
    "             train_set, \n",
    "             test_set, \n",
    "             n_epochs=200, \n",
    "             dampings=dampings, \n",
    "             log_interval=20,\n",
    "             exp='large-bs-0'\n",
    "            )\n",
    "write_stats(hist, 'large-bs-0', 'final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial BS 256, max batch size 5120\n",
    "\n",
    "# lr and bs\n",
    "orig_lr = 0.05\n",
    "orig_bs = 128\n",
    "# exp\n",
    "exp_lr = orig_lr * 2\n",
    "exp_bs = orig_bs * 2\n",
    "exp_momentum = 0.98\n",
    "# damping sched\n",
    "dampings = {\n",
    "    0:   exp_bs,\n",
    "    60:  exp_bs * 5,\n",
    "    120: exp_bs * 5 * 5,\n",
    "    180: exp_bs * 5 * 5 * 5,\n",
    "}\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "args = dict(\n",
    "    module=Wide_ResNet,\n",
    "    module__depth=16,\n",
    "    module__widen_factor=4,\n",
    "    module__dropout_rate=0.3,\n",
    "    module__num_classes=len(classes),\n",
    "    loss=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer__lr=exp_lr,\n",
    "    optimizer__momentum=exp_momentum,\n",
    "    optimizer__nesterov=True,\n",
    "    optimizer__weight_decay=0.5e-3,\n",
    "    max_epochs=200,\n",
    "    device=device,\n",
    "    grads_per_worker=128,\n",
    "    client=client,\n",
    "    max_batch_size=5120,\n",
    "    lr=exp_lr,\n",
    "    batch_size=exp_bs\n",
    ")\n",
    "# set up\n",
    "model = DaskClassifierExpiriments(**args)\n",
    "# train\n",
    "hist = None\n",
    "with performance_report(filename=\"dask-report.html\"):\n",
    "    hist = train(model, \n",
    "             train_set, \n",
    "             test_set, \n",
    "             n_epochs=200, \n",
    "             dampings=dampings, \n",
    "             log_interval=20,\n",
    "             exp='large-bs-1'\n",
    "            )\n",
    "write_stats(hist, 'large-bs-1', 'final')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adadamp",
   "language": "python",
   "name": "adadamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
