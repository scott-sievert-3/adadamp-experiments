{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate running on multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/joeholt/Developer/next-lab/adadamp-experiments/')\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "from adadamp.adadamp import DaskClassifierSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://192.168.0.103/56901/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://192.168.0.103:8787/status' target='_blank'>http://192.168.0.103:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://192.168.0.103/56901/1' processes=1 threads=8, memory=17.18 GB>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training client\n",
    "from dask.distributed import Client\n",
    "\n",
    "def _prep():\n",
    "    from distributed.protocol import torch\n",
    "\n",
    "client = Client(processes=False)\n",
    "client.run(_prep)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_set, test_set, sim_data, n_epochs=200, log_interval=1):\n",
    "    \"\"\"\n",
    "    Train based on expiriment params\n",
    "    \n",
    "    Parameters:\n",
    "    epoch_sched: update lr and bs at epochs in this list\n",
    "    lr_sched: update lr to value at matching epoch. Should be same length as epoch_sched\n",
    "    bs_sched: update bs to value at matching epoch. Should be same length as epoch_sched\n",
    "    \"\"\"\n",
    "    assert len(epoch_sched) == len(lr_sched) == len(bs_sched), \"Invalid schedules. Epoch, lr and bs schedules should all be the same length.\"\n",
    "    \n",
    "    \n",
    "    history = []\n",
    "    for epoch in range(n_epochs):\n",
    "        sim = sim_data.pop(0)\n",
    "        model.set_sim(sim)\n",
    "        # run\n",
    "        print(\"[Epoch {}]\".format(epoch), end=\"\")\n",
    "        model.partial_fit(train_set)\n",
    "        score = model.score(test_set)\n",
    "        datum = {\"epoch\": epoch, \"score\": score, **model.get_params(), **model.meta_}\n",
    "        print(\" Score: {}\".format(score))\n",
    "        history.append(datum)\n",
    "        \n",
    "        if epoch % log_interval == 0:\n",
    "            write_stats(history, exp, 'ep{}'.format(epoch))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Wide_ResNet\n",
    "\n",
    "client.upload_file(\"./exp-dask/model.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./exp-dask/stats/decreasing-lr/exp--final.csv\"\n",
    "stats_df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "args = dict(\n",
    "    stats_df=stats_df,\n",
    "    module=Wide_ResNet,\n",
    "    module__depth=16,\n",
    "    module__widen_factor=4,\n",
    "    module__dropout_rate=0.3,\n",
    "    module__num_classes=len(classes),\n",
    "    loss=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer__lr=0.1,\n",
    "    optimizer__momentum=0.9,\n",
    "    optimizer__nesterov=True,\n",
    "    optimizer__weight_decay=0.5e-3,\n",
    "    batch_size=128,\n",
    "    max_epochs=200,\n",
    "    device=device,\n",
    "    grads_per_worker=128,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DaskClassifierSimulator(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "model.initialize()\n",
    "print(model._sim_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      epoch   score                       module  \\\n",
       "0        0  0.5991  <class 'model.Wide_ResNet'>   \n",
       "1        1  0.6763  <class 'model.Wide_ResNet'>   \n",
       "2        2  0.7157  <class 'model.Wide_ResNet'>   \n",
       "3        3  0.7778  <class 'model.Wide_ResNet'>   \n",
       "4        4  0.7679  <class 'model.Wide_ResNet'>   \n",
       "..     ...     ...                          ...   \n",
       "195    195  0.9195  <class 'model.Wide_ResNet'>   \n",
       "196    196  0.9190  <class 'model.Wide_ResNet'>   \n",
       "197    197  0.9204  <class 'model.Wide_ResNet'>   \n",
       "198    198  0.9211  <class 'model.Wide_ResNet'>   \n",
       "199    199  0.9205  <class 'model.Wide_ResNet'>   \n",
       "\n",
       "                                                 loss  \\\n",
       "0    <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
       "1    <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
       "2    <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
       "3    <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
       "4    <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
       "..                                                ...   \n",
       "195  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
       "196  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
       "197  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
       "198  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
       "199  <class 'torch.nn.modules.loss.CrossEntropyLoss'>   \n",
       "\n",
       "                         optimizer  metrics  device  cluster  \\\n",
       "0    <class 'torch.optim.sgd.SGD'>      NaN  cuda:0      NaN   \n",
       "1    <class 'torch.optim.sgd.SGD'>      NaN  cuda:0      NaN   \n",
       "2    <class 'torch.optim.sgd.SGD'>      NaN  cuda:0      NaN   \n",
       "3    <class 'torch.optim.sgd.SGD'>      NaN  cuda:0      NaN   \n",
       "4    <class 'torch.optim.sgd.SGD'>      NaN  cuda:0      NaN   \n",
       "..                             ...      ...     ...      ...   \n",
       "195  <class 'torch.optim.sgd.SGD'>      NaN  cuda:0      NaN   \n",
       "196  <class 'torch.optim.sgd.SGD'>      NaN  cuda:0      NaN   \n",
       "197  <class 'torch.optim.sgd.SGD'>      NaN  cuda:0      NaN   \n",
       "198  <class 'torch.optim.sgd.SGD'>      NaN  cuda:0      NaN   \n",
       "199  <class 'torch.optim.sgd.SGD'>      NaN  cuda:0      NaN   \n",
       "\n",
       "     grads_per_worker  max_epochs  ...  score__calls  partial_fit__calls  \\\n",
       "0                 128         200  ...             1                   1   \n",
       "1                 128         200  ...             2                   2   \n",
       "2                 128         200  ...             3                   3   \n",
       "3                 128         200  ...             4                   4   \n",
       "4                 128         200  ...             5                   5   \n",
       "..                ...         ...  ...           ...                 ...   \n",
       "195               128         200  ...           200                 196   \n",
       "196               128         200  ...           201                 197   \n",
       "197               128         200  ...           202                 198   \n",
       "198               128         200  ...           203                 199   \n",
       "199               128         200  ...           204                 200   \n",
       "\n",
       "     n_workers  partial_fit__time  partial_fit__batch_size  partial_fit__lr  \\\n",
       "0            1          75.399943                      128           0.0500   \n",
       "1            1          76.574968                      128           0.0500   \n",
       "2            1          77.848670                      128           0.0500   \n",
       "3            1          78.652740                      128           0.0500   \n",
       "4            1          79.629816                      128           0.0500   \n",
       "..         ...                ...                      ...              ...   \n",
       "195          1          81.082111                      128           0.0004   \n",
       "196          1          82.212702                      128           0.0004   \n",
       "197          1          81.176804                      128           0.0004   \n",
       "198          1          80.922803                      128           0.0004   \n",
       "199          1          80.923284                      128           0.0004   \n",
       "\n",
       "     weight_aggregate  score__acc  score__loss  score__time  \n",
       "0         2852.472614      0.5991     1.162153     4.900564  \n",
       "1         3337.492528      0.6763     0.938337     4.999458  \n",
       "2         3546.287621      0.7157     0.828155     5.053349  \n",
       "3         3737.252048      0.7778     0.645094     5.292721  \n",
       "4         3813.815492      0.7679     0.671039     5.270049  \n",
       "..                ...         ...          ...          ...  \n",
       "195       3038.138605      0.9195     0.276623     5.369393  \n",
       "196       3036.418360      0.9190     0.271468     5.368083  \n",
       "197       3034.252175      0.9204     0.266218     5.396209  \n",
       "198       3032.991518      0.9211     0.270497     5.378564  \n",
       "199       3031.649706      0.9205     0.271296     5.487259  \n",
       "\n",
       "[200 rows x 37 columns]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adadamp",
   "language": "python",
   "name": "adadamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
