{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate running on multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/joeholt/Developer/next-lab/adadamp-experiments/')\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "from adadamp.adadamp import DaskClassifierSimulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>inproc://10.139.67.201/51337/1</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.139.67.201:8787/status' target='_blank'>http://10.139.67.201:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>17.18 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'inproc://10.139.67.201/51337/1' processes=1 threads=8, memory=17.18 GB>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training client\n",
    "from dask.distributed import Client\n",
    "\n",
    "def _prep():\n",
    "    from distributed.protocol import torch\n",
    "\n",
    "client = Client(processes=False)\n",
    "client.run(_prep)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./exp-dask/data', train=True, download=True, transform=transform_train)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./exp-dask/data', train=False, download=True, transform=transform_test)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_stats(hist, directory, filename):\n",
    "    toCSV = hist\n",
    "    with open('./exp-dask/{}/{}'.format(directory, filename), 'w', encoding='utf8', newline='') as output_file:\n",
    "        fc = csv.DictWriter(output_file, fieldnames=toCSV[0].keys())\n",
    "        fc.writeheader()\n",
    "        fc.writerows(toCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_set, test_set, stats_df, n_epochs=200, log_interval=1, stats_dir=''):\n",
    "    \"\"\"\n",
    "    Train based on expiriment params\n",
    "    \n",
    "    Parameters:\n",
    "    epoch_sched: update lr and bs at epochs in this list\n",
    "    lr_sched: update lr to value at matching epoch. Should be same length as epoch_sched\n",
    "    bs_sched: update bs to value at matching epoch. Should be same length as epoch_sched\n",
    "    \"\"\"\n",
    "    \n",
    "    stats = list(stats_df.T.to_dict().values())\n",
    "    print(\"[SETUP] Loaded {} epochs of stats\".format(len(stats)))\n",
    "    \n",
    "    history = []\n",
    "    for epoch in range(min(n_epochs, len(stats))):\n",
    "        \n",
    "        # set stats\n",
    "        stat = stats.pop(0)\n",
    "        model.set_sim(stat)\n",
    "        \n",
    "        # run\n",
    "        print(\"[Epoch {}]\".format(epoch), end=\"\")\n",
    "        model.partial_fit(train_set)\n",
    "        score = model.score(test_set)\n",
    "        datum = {\"epoch\": epoch, \"score\": score, **model.get_params(), **model.meta_}\n",
    "        print(\" Score: {}\".format(score))\n",
    "        history.append(datum)\n",
    "        \n",
    "        if epoch % log_interval == 0:\n",
    "            write_stats(history, stats_dir, 'results-ep{}.csv'.format(epoch))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Wide_ResNet\n",
    "\n",
    "client.upload_file(\"./exp-dask/model.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" if not torch.cuda.is_available() else \"cuda:0\"\n",
    "args = dict(\n",
    "    module=Wide_ResNet,\n",
    "    module__depth=16,\n",
    "    module__widen_factor=4,\n",
    "    module__dropout_rate=0.3,\n",
    "    module__num_classes=len(classes),\n",
    "    loss=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer__lr=0.1,\n",
    "    optimizer__momentum=0.9,\n",
    "    optimizer__nesterov=True,\n",
    "    optimizer__weight_decay=0.5e-3,\n",
    "    batch_size=128,\n",
    "    max_epochs=200,\n",
    "    device=device,\n",
    "    grads_per_worker=128,\n",
    "    client=client\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SETUP] Loaded 200 epochs of stats\n",
      "[Epoch 0] Score: 0.5990999937057495\n",
      "[Epoch 1] Score: 0.6762999892234802\n",
      "[Epoch 2] Score: 0.7156999707221985\n",
      "[Epoch 3] Score: 0.7777999639511108\n",
      "[Epoch 4] Score: 0.7678999900817871\n",
      "[Epoch 5] Score: 0.7994999885559082\n",
      "[Epoch 6] Score: 0.8030999898910522\n",
      "[Epoch 7] Score: 0.8100000023841858\n",
      "[Epoch 8] Score: 0.8186999559402466\n",
      "[Epoch 9] Score: 0.8077999949455261\n",
      "[Epoch 10] Score: 0.8211999535560608\n",
      "[Epoch 11] Score: 0.8321999907493591\n",
      "[Epoch 12] Score: 0.8306999802589417\n",
      "[Epoch 13] Score: 0.8325999975204468\n",
      "[Epoch 14] Score: 0.8138999938964844\n",
      "[Epoch 15] Score: 0.8307999968528748\n",
      "[Epoch 16] Score: 0.817799985408783\n",
      "[Epoch 17] Score: 0.8342999815940857\n",
      "[Epoch 18] Score: 0.8316999673843384\n",
      "[Epoch 19] Score: 0.8359999656677246\n",
      "[Epoch 20] Score: 0.8330999612808228\n",
      "[Epoch 21] Score: 0.8362999558448792\n",
      "[Epoch 22] Score: 0.8465999960899353\n",
      "[Epoch 23] Score: 0.8337999582290649\n",
      "[Epoch 24] Score: 0.8400999903678894\n",
      "[Epoch 25] Score: 0.8458999991416931\n",
      "[Epoch 26] Score: 0.8483999967575073\n",
      "[Epoch 27] Score: 0.848800003528595\n",
      "[Epoch 28] Score: 0.8422999978065491\n",
      "[Epoch 29] Score: 0.8422999978065491\n",
      "[Epoch 30] Score: 0.8551999926567078\n",
      "[Epoch 31] Score: 0.8567000031471252\n",
      "[Epoch 32] Score: 0.8396999835968018\n",
      "[Epoch 33] Score: 0.8459999561309814\n",
      "[Epoch 34] Score: 0.8452999591827393\n",
      "[Epoch 35] Score: 0.8454999923706055\n",
      "[Epoch 36] Score: 0.8418999910354614\n",
      "[Epoch 37] Score: 0.8481999635696411\n",
      "[Epoch 38] Score: 0.857699990272522\n",
      "[Epoch 39] Score: 0.8452000021934509\n",
      "[Epoch 40] Score: 0.8454999923706055\n",
      "[Epoch 41] Score: 0.8567999601364136\n",
      "[Epoch 42] Score: 0.8613999485969543\n",
      "[Epoch 43] Score: 0.8549999594688416\n",
      "[Epoch 44] Score: 0.8486999869346619\n",
      "[Epoch 45] Score: 0.8531999588012695\n",
      "[Epoch 46] Score: 0.8583999872207642\n",
      "[Epoch 47] Score: 0.8504999876022339\n",
      "[Epoch 48] Score: 0.8517999649047852\n",
      "[Epoch 49] Score: 0.8423999547958374\n",
      "[Epoch 50] Score: 0.858199954032898\n",
      "[Epoch 51] Score: 0.8578000068664551\n",
      "[Epoch 52] Score: 0.8549000024795532\n",
      "[Epoch 53] Score: 0.8698999881744385\n",
      "[Epoch 54] Score: 0.8524999618530273\n",
      "[Epoch 55] Score: 0.8477999567985535\n",
      "[Epoch 56] Score: 0.8549000024795532\n",
      "[Epoch 57] Score: 0.838699996471405\n",
      "[Epoch 58]"
     ]
    }
   ],
   "source": [
    "model = DaskClassifierSimulator(**args)\n",
    "stats_df = pd.read_csv('./exp-dask/stats/decreasing-lr/exp--final.csv')\n",
    "# train\n",
    "hist = train(model, \n",
    "         train_set, \n",
    "         test_set, \n",
    "         stats_df,\n",
    "         n_epochs=200, \n",
    "         log_interval=20,\n",
    "         stats_dir=\"sim-results/dec-lr\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_stats(history, 'sim-results/dec-lr', 'results-final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adadamp",
   "language": "python",
   "name": "adadamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
